{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLxPEz0B_bVP",
    "outputId": "0dc0dac8-92d8-4dad-d46b-0b789eeeac20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PO8NiS0M_cVE",
    "outputId": "9c2cb2c0-0ef1-42a2-b508-7a2c9a213563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-mxjkzm9q\n",
      "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-mxjkzm9q\n",
      "Building wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=308296755d14180c0bc9969c7f275d0f78b3c962c5daa51761a27f8beb97c6a4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cycfes0h/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
      "Successfully built NVCCPlugin\n",
      "Installing collected packages: NVCCPlugin\n",
      "Successfully installed NVCCPlugin-0.0.2\n",
      "created output directory at /content/src\n",
      "Out bin /content/result.out\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcoYPEmb_zIq",
    "outputId": "d47a999c-72a9-495f-e151-4eceae58bf5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "pzfzPAW8CgeJ",
    "outputId": "31214300-aabf-406a-dffa-8c38d2359ee4"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "bigquery": "Other",
        "capture": "ExecutionMagics",
        "cu": "NVCCPlugin",
        "cuda": "NVCCPluginV2",
        "cuda_run": "NVCCPluginV2",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "shell": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "Other",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "shell": "Other",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "tensorflow_version": "Other",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %shell  %store  %sx  %system  %tb  %tensorflow_version  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%bigquery  %%capture  %%cu  %%cuda  %%cuda_run  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%shell  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2j1SHOXghHI_",
    "outputId": "3ffebd1e-dd40-40d7-cb8d-9e19776e7060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sequential.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile sequential.cpp\n",
    "#include<stdio.h>\n",
    "#include <bits/stdc++.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "void get_adj_matrix(float* graph, int n, float d, FILE *inputFilePtr ){\n",
    "\n",
    "    if ( inputFilePtr == NULL )  {\n",
    "        printf( \"input.txt file failed to open.\" );\n",
    "        return ;\n",
    "    }\n",
    "\n",
    "    int m, indexing;\n",
    "    \n",
    "    fscanf(inputFilePtr, \"%d\", &m);\n",
    "    fscanf(inputFilePtr, \"%d\", &indexing);\n",
    "\n",
    "    \n",
    "    for(int i = 0; i< n ; i++){\n",
    "    \n",
    "        for(int j = 0; j< n; ++j){\n",
    "            graph[i* n + j] = (1 - d)/float(n);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    while(m--){\n",
    "        int source, destin;\n",
    "        fscanf(inputFilePtr, \"%d\", &source);\n",
    "        fscanf(inputFilePtr, \"%d\", &destin);\n",
    "        if (indexing == 0){\n",
    "            graph[destin* n + source] += d* 1.0  ;\n",
    "        }\n",
    "        else{\n",
    "            graph[(destin - 1)* n + source - 1] += d* 1.0;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "void manage_adj_matrix(float* graph, int n){\n",
    "\n",
    "    for(int j = 0; j < n; ++j){\n",
    "        float sum = 0.0;\n",
    "\n",
    "        for (int i = 0; i< n; ++i){\n",
    "            sum += graph[i* n + j];\n",
    "        }\n",
    "\n",
    "        for (int i = 0; i < n; ++i){\n",
    "            if (sum != 0.0){\n",
    "                graph[i*n + j] /= sum;\n",
    "            }\n",
    "            else{\n",
    "                graph[i*n + j] = (1/(float)n);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n",
    "float norm(float *vect, int n){\n",
    "    float ans = 0.0;\n",
    "    for (int i = 0; i < n; ++i){\n",
    "        ans += abs(vect[i]);\n",
    "    }\n",
    "    return ans;\n",
    "}\n",
    "\n",
    "void power_method(float *graph, float *r, int n, int max_iter = 1000, float eps = 0.000001 ){\n",
    "   \n",
    "    float* r_last = (float*) malloc(n * sizeof(float));\n",
    "    \n",
    "\n",
    "    for(int i = 0; i< n; ++i){\n",
    "        r[i] = (1/(float)n);\n",
    "    }\n",
    "\n",
    "    while(max_iter--){\n",
    "        for(int i = 0; i< n; ++i){\n",
    "            r_last[i] = r[i];\n",
    "        }\n",
    "        for(int i = 0; i< n; ++i){\n",
    "            float sum = 0.0;\n",
    "\n",
    "            for (int j = 0; j< n; ++j){\n",
    "                sum += r_last[j] * graph[i* n + j];\n",
    "            }\n",
    "\n",
    "            r[i] = sum;\n",
    "\n",
    "        }\n",
    "\n",
    "        for(int i = 0; i< n; ++i){\n",
    "            r_last[i] -= r[i];\n",
    "        }\n",
    "\n",
    "        if(norm(r_last, n) < eps){\n",
    "            return;\n",
    "        }\n",
    "\n",
    "    }\n",
    "    return;\n",
    "}\n",
    "\n",
    "void top_nodes(float *r, int n, int count = 3){\n",
    "\n",
    "    priority_queue<pair<float, int>> pq;\n",
    "\n",
    "    for(int i = 0; i< n; ++i){\n",
    "        pq.push(make_pair(r[i], i+ 1));\n",
    "    }\n",
    "    int rank =1;\n",
    "    while(rank <= count){\n",
    "        printf(\"Rank %d Node is %d\\n\", rank, pq.top().second);\n",
    "        rank++;\n",
    "        pq.pop();\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    clock_t start, end;\n",
    "\n",
    "    FILE *inputFilePtr;\n",
    "\n",
    "    char * inputfile = argv[1];\n",
    "    inputFilePtr = fopen(inputfile, \"r\");\n",
    "\n",
    "    int n; \n",
    "    fscanf(inputFilePtr, \"%d\", &n);\n",
    "\n",
    "    float d = 0.85; \n",
    "\n",
    "    float* graph = (float*)malloc(n *n* sizeof(float));\n",
    "\n",
    "\n",
    "    float* r = (float*) malloc(n * sizeof(float));\n",
    "\n",
    "   \n",
    "    get_adj_matrix(graph, n, d, inputFilePtr);\n",
    "\n",
    "    start = clock();\n",
    "\n",
    "    manage_adj_matrix(graph, n);\n",
    "    power_method(graph, r, n);\n",
    "    //top_nodes(r, n);\n",
    "\n",
    "    end = clock();\n",
    "\n",
    "    printf(\"Time taken :%f for sequential implementation with %d nodes.\\n\", float(end - start), n);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2z4AFmPloZG2",
    "outputId": "2900b305-d589-490e-9b04-00f083ba63bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken :392.000000 for sequential implementation with 100 nodes.\n",
      "Time taken :239.000000 for sequential implementation with 100 nodes.\n",
      "Time taken :6485.000000 for sequential implementation with 200 nodes.\n",
      "Time taken :3366.000000 for sequential implementation with 400 nodes.\n",
      "Time taken :20242.000000 for sequential implementation with 800 nodes.\n",
      "Time taken :2970832.000000 for sequential implementation with 1000 nodes.\n",
      "Time taken :67973952.000000 for sequential implementation with 4772 nodes.\n",
      "Time taken :67280016.000000 for sequential implementation with 9664 nodes.\n",
      "Time taken :26965332.000000 for sequential implementation with 16062 nodes.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "cd /content/\n",
    "g++ sequential.cpp\n",
    "./a.out 100_2.txt\n",
    "./a.out 100.txt\n",
    "./a.out 200.txt\n",
    "./a.out 400.txt\n",
    "./a.out 800.txt\n",
    "./a.out 1000.txt\n",
    "./a.out 5000.txt\n",
    "./a.out 10000.txt\n",
    "./a.out 16000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "IB6g6y-w0KnI",
    "outputId": "12d8daa3-cc00-4793-b61c-fff11671adca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1364418560 bytes == 0x55a37d16c000 @  0x7f8f2863c1e7 0x55a37b2c3377 0x7f8f27c98bf7 0x55a37b2c2b6a\n",
      "Rank 1 Node is 4949\n",
      "Rank 2 Node is 11833\n",
      "Rank 3 Node is 5461\n",
      "Time taken :1030231744.000000 for sequential implementation with 18469 nodes.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "cd /content/\n",
    "g++ sequential.cpp\n",
    "\n",
    "./a.out 18000.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "HfhyednS0TT5",
    "outputId": "66dec81a-b18e-44bb-a5ba-681a975a62c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parallel.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile parallel.cu\n",
    "#include<stdio.h>\n",
    "#include <bits/stdc++.h>\n",
    "#include<cuda.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/sort.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "\n",
    "void get_adj_matrix(float* graph, int n, float d, FILE *inputFilePtr ){\n",
    "\n",
    "    if ( inputFilePtr == NULL )  {\n",
    "        printf( \"input.txt file failed to open.\" );\n",
    "        return ;\n",
    "    }\n",
    "\n",
    "    int m, indexing;\n",
    "    \n",
    "    fscanf(inputFilePtr, \"%d\", &m);\n",
    "    fscanf(inputFilePtr, \"%d\", &indexing);\n",
    "\n",
    "    \n",
    "    for(int i = 0; i< n ; i++){\n",
    "    \n",
    "        for(int j = 0; j< n; ++j){\n",
    "            graph[i* n + j] = (1 - d)/float(n);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    while(m--){\n",
    "        int source, destin;\n",
    "        fscanf(inputFilePtr, \"%d\", &source);\n",
    "        fscanf(inputFilePtr, \"%d\", &destin);\n",
    "        if (indexing == 0){\n",
    "            graph[destin* n + source] += d* 1.0  ;\n",
    "        }\n",
    "        else{\n",
    "            graph[(destin - 1)* n + source - 1] += d* 1.0;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void manage_adj_matrix(float* gpu_graph, int n){\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(id < n){\n",
    "        float sum = 0.0;\n",
    "\n",
    "        for (int i = 0; i< n; ++i){\n",
    "            sum += gpu_graph[i* n + id];\n",
    "        }\n",
    "\n",
    "        for (int i = 0; i < n; ++i){\n",
    "            if (sum != 0.0){\n",
    "                gpu_graph[i* n + id] /= sum;\n",
    "            }\n",
    "            else{\n",
    "                gpu_graph[i* n + id] = (1/(float)n);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void initialize_rank(float* gpu_r, int n){\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if(id < n){\n",
    "        gpu_r[id] = (1/(float)n);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void store_rank(float* gpu_r,float* gpu_r_last, int n){\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if(id < n){\n",
    "        gpu_r_last[id] = gpu_r[id];\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void matmul(float* gpu_graph, float* gpu_r, float* gpu_r_last, int n){\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if(id < n){\n",
    "        float sum = 0.0;\n",
    "\n",
    "        for (int j = 0; j< n; ++j){\n",
    "            sum += gpu_r_last[j] * gpu_graph[id* n + j];\n",
    "        }\n",
    "\n",
    "        gpu_r[id] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void rank_diff(float* gpu_r,float* gpu_r_last, int n){\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if(id < n){\n",
    "        gpu_r_last[id] = abs(gpu_r_last[id] - gpu_r[id]);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void init_pair_array(pair<float, int>* gpu_r_nodes, float * gpu_r, int n){\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if(id < n){\n",
    "        gpu_r_nodes[id].first = gpu_r[id];\n",
    "        gpu_r_nodes[id].second = id + 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "void power_method(float *graph, float *r, int n, int nblocks, int BLOCKSIZE, int max_iter = 1000, float eps = 0.000001 ){\n",
    "   \n",
    "    float* r_last = (float*) malloc(n * sizeof(float));\n",
    "    \n",
    "    float* gpu_graph;\n",
    "    cudaMalloc(&gpu_graph, sizeof(float)*n*n);\n",
    "    cudaMemcpy(gpu_graph, graph, sizeof(float)*n*n, cudaMemcpyHostToDevice);\n",
    "\n",
    "    float* gpu_r;\n",
    "    cudaMalloc(&gpu_r, sizeof(float)*n);\n",
    "    //cudaMemcpy(gpu_r, r, sizeof(float)*n, cudaMemcpyHostToDevice);\n",
    "\n",
    "    float* gpu_r_last;\n",
    "    cudaMalloc(&gpu_r_last, sizeof(float)*n);\n",
    "    //cudaMemcpy(gpu_r_last, r_last, sizeof(float)*n, cudaMemcpyHostToDevice);\n",
    "\n",
    "\n",
    "\n",
    "    initialize_rank<<<nblocks, BLOCKSIZE>>>(gpu_r, n);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "\n",
    "\n",
    "    while(max_iter--){\n",
    "\n",
    "        store_rank<<<nblocks, BLOCKSIZE>>>(gpu_r, gpu_r_last, n);\n",
    "        cudaDeviceSynchronize();\n",
    "\n",
    "        matmul<<<nblocks, BLOCKSIZE>>>(gpu_graph, gpu_r, gpu_r_last, n);\n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        rank_diff<<<nblocks, BLOCKSIZE>>>(gpu_r, gpu_r_last, n);\n",
    "        cudaDeviceSynchronize();\n",
    "\n",
    "        cudaMemcpy(r_last, gpu_r_last, n* sizeof(float), cudaMemcpyDeviceToHost);\n",
    "        float result = thrust::reduce( r_last, r_last + n);\n",
    "\n",
    "        if(result < eps){\n",
    "            cudaMemcpy(r, gpu_r, n* sizeof(float), cudaMemcpyDeviceToHost);\n",
    "            return;\n",
    "        }\n",
    "    }\n",
    "    cudaMemcpy(r, gpu_r, n* sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    return;\n",
    "}\n",
    "\n",
    "void top_nodes(float* r, int n, int nblocks, int BLOCKSIZE, int count = 3){\n",
    "\n",
    "    pair<float, int> *r_nodes = (pair<float, int> *) malloc ( n * sizeof (pair<float, int>) );\n",
    "    pair<float, int> *gpu_r_nodes;\n",
    "\n",
    "    cudaMalloc(&gpu_r_nodes, n * sizeof (pair<float, int>));\n",
    "\n",
    "    float* gpu_r;\n",
    "    cudaMalloc(&gpu_r, sizeof(float)*n);\n",
    "    cudaMemcpy(gpu_r, r, sizeof(float)*n, cudaMemcpyHostToDevice);\n",
    "\n",
    "    init_pair_array<<<nblocks, BLOCKSIZE>>>(gpu_r_nodes, gpu_r, n);\n",
    "\n",
    "    cudaMemcpy(r_nodes, gpu_r_nodes, n * sizeof (pair<float, int>), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    thrust::sort(thrust::host, r_nodes, r_nodes + n);\n",
    "\n",
    "    int rank =1;\n",
    "    while(rank <= count){\n",
    "        printf(\"Rank %d Node is %d\\n\", rank, r_nodes[n - rank].second);\n",
    "        rank++;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    clock_t start, end;\n",
    "\n",
    "    FILE *inputFilePtr;\n",
    "\n",
    "    char * inputfile = argv[1];\n",
    "\n",
    "    char * bsize = argv[2];\n",
    "    int BLOCKSIZE = atoi(bsize);\n",
    "\n",
    "    inputFilePtr = fopen(inputfile, \"r\");\n",
    "\n",
    "    int n; \n",
    "\n",
    "    fscanf(inputFilePtr, \"%d\", &n);\n",
    "    int nblocks = ceil(float(n) / BLOCKSIZE);\n",
    "\n",
    "    float* graph = (float*)malloc(n*n*sizeof(float));\n",
    "    float* r = (float*) malloc(n * sizeof(float));\n",
    "\n",
    "    float d = 0.85;\n",
    "\n",
    "    get_adj_matrix(graph, n, d, inputFilePtr);\n",
    "\n",
    "    float* gpu_graph;\n",
    "    cudaMalloc(&gpu_graph, sizeof(float)*n*n);\n",
    "    cudaMemcpy(gpu_graph, graph, sizeof(float)*n*n, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    start = clock();\n",
    "\n",
    "    manage_adj_matrix<<<nblocks, BLOCKSIZE>>>(gpu_graph, n);\n",
    "    cudaMemcpy(graph, gpu_graph, sizeof(float)*n*n, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    power_method(graph, r, n, nblocks, BLOCKSIZE );\n",
    "\n",
    "    //top_nodes(r, n, nblocks, BLOCKSIZE);\n",
    "\n",
    "    end = clock();\n",
    "\n",
    "    printf(\"Time taken :%f for parallel implementation with %d nodes and %d threads per block.\\n\", float(end - start), n, BLOCKSIZE);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nzabKfUUnX-U",
    "outputId": "6955c699-7f0c-4fe1-9fe5-e5a1db57bd1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/assign_value.h(36): warning: calling a __host__ function from a __host__ __device__ function is not allowed\n",
      "          detected during:\n",
      "            instantiation of \"void thrust::system::detail::sequential::assign_value(thrust::system::detail::sequential::execution_policy<DerivedPolicy> &, Pointer1, Pointer2) [with DerivedPolicy=thrust::system::cpp::detail::tag, Pointer1=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Pointer2=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(183): here\n",
      "            instantiation of \"void thrust::reference<Element, Pointer, Derived>::strip_const_assign_value(const System &, OtherPointer) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default, System=thrust::system::cpp::detail::tag, OtherPointer=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(149): here\n",
      "            instantiation of \"void thrust::reference<Element, Pointer, Derived>::assign_from(System1 *, System2 *, OtherPointer) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default, System1=thrust::system::cpp::detail::par_t, System2=thrust::host_system_tag, OtherPointer=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(169): here\n",
      "            instantiation of \"void thrust::reference<Element, Pointer, Derived>::assign_from(OtherPointer) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default, OtherPointer=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(69): here\n",
      "            instantiation of \"thrust::reference<Element, Pointer, Derived>::derived_type &thrust::reference<Element, Pointer, Derived>::operator=(const thrust::reference<Element, Pointer, Derived>::value_type &) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl(58): here\n",
      "            [ 7 instantiation contexts not shown ]\n",
      "            instantiation of \"void thrust::stable_sort(const thrust::detail::execution_policy_base<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator, StrictWeakOrdering) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *, StrictWeakOrdering=thrust::less<std::pair<float, int>>]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/sort.inl(63): here\n",
      "            instantiation of \"void thrust::system::detail::generic::sort(thrust::execution_policy<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator, StrictWeakOrdering) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *, StrictWeakOrdering=thrust::less<std::pair<float, int>>]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/sort.inl(56): here\n",
      "            instantiation of \"void thrust::sort(const thrust::detail::execution_policy_base<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator, StrictWeakOrdering) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *, StrictWeakOrdering=thrust::less<std::pair<float, int>>]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/sort.inl(49): here\n",
      "            instantiation of \"void thrust::system::detail::generic::sort(thrust::execution_policy<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/sort.inl(41): here\n",
      "            instantiation of \"void thrust::sort(const thrust::detail::execution_policy_base<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *]\" \n",
      "parallel.cu(173): here\n",
      "\n",
      "Time taken :593.000000 for parallel implementation with 100 nodes and 32 threads per block.\n",
      "Time taken :408.000000 for parallel implementation with 100 nodes and 32 threads per block.\n",
      "Time taken :2152.000000 for parallel implementation with 200 nodes and 32 threads per block.\n",
      "Time taken :936.000000 for parallel implementation with 400 nodes and 32 threads per block.\n",
      "Time taken :2356.000000 for parallel implementation with 800 nodes and 32 threads per block.\n",
      "Time taken :104831.000000 for parallel implementation with 1000 nodes and 32 threads per block.\n",
      "Time taken :816446.000000 for parallel implementation with 4772 nodes and 32 threads per block.\n",
      "Time taken :755148.000000 for parallel implementation with 9664 nodes and 32 threads per block.\n",
      "Time taken :626986.000000 for parallel implementation with 16062 nodes and 32 threads per block.\n",
      "tcmalloc: large alloc 1364418560 bytes == 0x55fc3a780000 @  0x7fc9e2d381e7 0x55fc38032243 0x7fc9e1d69bf7 0x55fc380316da\n",
      "Time taken :15588785.000000 for parallel implementation with 18469 nodes and 32 threads per block.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "cd /content/\n",
    "nvcc parallel.cu\n",
    "./a.out 100_2.txt 32\n",
    "./a.out 100.txt 32\n",
    "./a.out 200.txt 32\n",
    "./a.out 400.txt 32\n",
    "./a.out 800.txt 32\n",
    "./a.out 1000.txt 32\n",
    "./a.out 5000.txt 32\n",
    "./a.out 10000.txt 32\n",
    "./a.out 16000.txt 32\n",
    "./a.out 18000.txt 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rukeeZN8DBr"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "cd /content/\n",
    "nvcc parallel.cu\n",
    "\n",
    "./a.out 18000.txt 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LWFuj__vY-Lg",
    "outputId": "fb435e41-f2f5-422b-deb4-f16bf33cc646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/assign_value.h(36): warning: calling a __host__ function from a __host__ __device__ function is not allowed\n",
      "          detected during:\n",
      "            instantiation of \"void thrust::system::detail::sequential::assign_value(thrust::system::detail::sequential::execution_policy<DerivedPolicy> &, Pointer1, Pointer2) [with DerivedPolicy=thrust::system::cpp::detail::tag, Pointer1=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Pointer2=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(183): here\n",
      "            instantiation of \"void thrust::reference<Element, Pointer, Derived>::strip_const_assign_value(const System &, OtherPointer) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default, System=thrust::system::cpp::detail::tag, OtherPointer=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(149): here\n",
      "            instantiation of \"void thrust::reference<Element, Pointer, Derived>::assign_from(System1 *, System2 *, OtherPointer) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default, System1=thrust::system::cpp::detail::par_t, System2=thrust::host_system_tag, OtherPointer=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(169): here\n",
      "            instantiation of \"void thrust::reference<Element, Pointer, Derived>::assign_from(OtherPointer) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default, OtherPointer=const std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/reference.inl(69): here\n",
      "            instantiation of \"thrust::reference<Element, Pointer, Derived>::derived_type &thrust::reference<Element, Pointer, Derived>::operator=(const thrust::reference<Element, Pointer, Derived>::value_type &) [with Element=std::pair<float, int>, Pointer=thrust::pointer<std::pair<float, int>, thrust::system::cpp::detail::par_t, thrust::use_default, thrust::use_default>, Derived=thrust::use_default]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl(58): here\n",
      "            [ 7 instantiation contexts not shown ]\n",
      "            instantiation of \"void thrust::stable_sort(const thrust::detail::execution_policy_base<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator, StrictWeakOrdering) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *, StrictWeakOrdering=thrust::less<std::pair<float, int>>]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/sort.inl(63): here\n",
      "            instantiation of \"void thrust::system::detail::generic::sort(thrust::execution_policy<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator, StrictWeakOrdering) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *, StrictWeakOrdering=thrust::less<std::pair<float, int>>]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/sort.inl(56): here\n",
      "            instantiation of \"void thrust::sort(const thrust::detail::execution_policy_base<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator, StrictWeakOrdering) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *, StrictWeakOrdering=thrust::less<std::pair<float, int>>]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/sort.inl(49): here\n",
      "            instantiation of \"void thrust::system::detail::generic::sort(thrust::execution_policy<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *]\" \n",
      "/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/sort.inl(41): here\n",
      "            instantiation of \"void thrust::sort(const thrust::detail::execution_policy_base<DerivedPolicy> &, RandomAccessIterator, RandomAccessIterator) [with DerivedPolicy=thrust::system::cpp::detail::par_t, RandomAccessIterator=std::pair<float, int> *]\" \n",
      "parallel.cu(173): here\n",
      "\n",
      "Time taken :950401.000000 for parallel implementation with 9664 nodes and 8 threads per block.\n",
      "Time taken :839092.000000 for parallel implementation with 9664 nodes and 16 threads per block.\n",
      "Time taken :752572.000000 for parallel implementation with 9664 nodes and 32 threads per block.\n",
      "Time taken :759962.000000 for parallel implementation with 9664 nodes and 64 threads per block.\n",
      "Time taken :868481.000000 for parallel implementation with 9664 nodes and 128 threads per block.\n",
      "Time taken :900917.000000 for parallel implementation with 9664 nodes and 256 threads per block.\n",
      "Time taken :2052449.000000 for parallel implementation with 9664 nodes and 512 threads per block.\n",
      "Time taken :3698519.000000 for parallel implementation with 9664 nodes and 1024 threads per block.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "cd /content/\n",
    "nvcc parallel.cu\n",
    "\n",
    "./a.out 10000.txt 8\n",
    "./a.out 10000.txt 16\n",
    "./a.out 10000.txt 32\n",
    "./a.out 10000.txt 64\n",
    "./a.out 10000.txt 128\n",
    "./a.out 10000.txt 256\n",
    "./a.out 10000.txt 512\n",
    "./a.out 10000.txt 1024"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pagerank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
